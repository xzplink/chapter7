#!/usr/bin/env python
# -*-coding:UTF-8-*-
# Create by zhaozhang@yxlink.com
# On 2017/01/022

import logging
import urllib2
import MySQLdb
import re
from HTMLParser import HTMLParser
import signal
import sys
import Queue
from threading import Thread
import time

# reload(sys)
# sys.setdefaultencoding('utf8')
HOST = "127.0.0.1"
DB_USER = "root"
DB_PASSWD = "yxserver"
DB_NAME = "waf_hw"
THREAD_NUM = 10
CVE_QUEUE = Queue.Queue()
CVE_INFO_QUEUE = Queue.Queue()
CVE_COUNTER = 0

class MyHtmlParser(HTMLParser):
    selected_key = ["colspan","nowrap"]
    cve_pattern = re.compile(r'^CVE[-\d]+$')
    url_pattern = re.compile(r'^URL:(http|ftp)://[\w\S]+')
    arg_pattern = re.compile(r'^\w+=\d+')

    def __init__(self):
        HTMLParser.__init__(self)
        self.cve_id = ""
        self.desc = []
        self.refer = []
        self.flag = False
        self.tag = False
        self.success = False

    def handle_starttag(self, tag, attrs):
        if tag == "td" and attrs:
            for (key, value) in attrs:
                if key in MyHtmlParser.selected_key:
                    self.flag = True
                    # print "key:",key
                    # print "value:",value.encode('utf8')
                else:
                    self.flag = False
        elif tag == "h2":
            self.flag = True

    def handle_data(self, data):
        if self.success:  # we have get all the info we need, so
            return    # jump out
        data = data.strip()
        if self.flag and data:
            match_cve = MyHtmlParser.cve_pattern.search(data)
            match_url = MyHtmlParser.url_pattern.search(data)
            arg_match = MyHtmlParser.arg_pattern.search(data)
            if match_cve:
                self.cve_id = data
                # print data
            elif match_url:
                # print data
                data = data[4:]
                self.refer.append(data)
            elif self.tag:
                self.desc.append(data)
                self.tag = False
            elif arg_match:
                # print data
                self.refer.append(data)
            else:
                # print "Encountered some data  :", data
                pass
        else:
            if data.find("Description") != -1:
                self.tag = True

    def handle_endtag(self, tag):
        if tag == "td":
            self.flag = False
        elif tag == "h2":
            self.flag = False
        elif tag == "ul":
            self.success = True

    def get_cve(self):
        return self.cve_id

    def get_desc(self):
        return self.desc

    def get_refer(self):
        return self.refer

def get_cve_id():
    global CVE_QUEUE,CVE_COUNTER
    try:
        conn = MySQLdb.connect(HOST, DB_USER, DB_PASSWD, db=DB_NAME, charset="utf8")
        cursor = conn.cursor(MySQLdb.cursors.DictCursor)
        sql = "SELECT DISTINCT cve FROM `vul_info` WHERE cve !='';"
        cursor.execute(sql)
        res = cursor.fetchall()
        cursor.close()
        conn.close()

        for row in res:
            cve_split = row['cve'].split(",")
            for i in range(len(cve_split)):
                CVE_QUEUE.put(cve_split[i])
                CVE_COUNTER += 1
        print "We have get :%d cve_id" % CVE_COUNTER

    except Exception,e:
        logging.error("get_cve_id failed," + str(e))

def download_html_file(url):
    global CVE_INFO_QUEUE
    try:
        headers = {
            "Accept":"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Encoding":"gzip, deflate, sdch",
            "Connection":"keep-alive",
            "User-Agent":"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.116 Safari/537.36"
        }
        request = urllib2.Request(url, headers=headers)
        f = urllib2.urlopen(request, timeout=5)
        retcode = f.getcode()
        # print retcode

        if int(retcode) == 200:
            doc = f.read()
            parser = MyHtmlParser()
            parser.feed(doc)
            # print doc
            tmp_dict = {'cve':'','desc':'','refer':''}
            tmp_dict['cve'] = parser.get_cve()
            tmp_dict['desc'] = parser.get_desc()[0]
            url_list = ""
            ref_list = parser.get_refer()
            tag = False
            for i in ref_list:
                if not tag:
                    if i.find("http:") != -1:
                        url_list += i
                    else:
                        print "Bad error, wrong ref list'"
                        url_list = ""
                        return  # pass it
                    tag = True
                elif i.find("http:") != -1:
                    url_list += "\n" + i
                else:
                    url_list += "&" + i

            tmp_dict['refer'] = url_list
            # print tmp_dict['cve']
            # print tmp_dict['desc']
            # print tmp_dict['refer']
            CVE_INFO_QUEUE.put(tmp_dict)
            print "[*] put one cve info into the Queue."

            parser.close()

    except Exception,e:
        logging.error("download_html_file failed," + str(e))

def upload_cve_info(cve_dict):
    try:
        conn = MySQLdb.connect(HOST, DB_USER, DB_PASSWD, db=DB_NAME, charset="utf8")
        cursor = conn.cursor(MySQLdb.cursors.DictCursor)
        # print cve_dict['cve']
        # print cve_dict['desc']
        # print cve_dict['refer']

        sql = "INSERT INTO cve_info_dev(`cve_id`,`abstract`,`ref`) VALUES(%s, %s, %s)"
        cursor.execute(sql, (cve_dict['cve'], cve_dict['desc'], cve_dict['refer']))
        conn.commit()

        cursor.close()
        conn.close()
    except Exception,e:
        logging.error("upload_cve_info failed," + str(e))

def upload_cve_info_handler():
    while True:
        while not CVE_INFO_QUEUE.empty():
            cve_dict = CVE_INFO_QUEUE.get()
            # print cve_dict
            print "[*] upload one cve info to mysql."
            upload_cve_info(cve_dict)
        time.sleep(1)
    print "[*] upload cve info thread is end."

def spider_cve_info_handler():
    while not CVE_QUEUE.empty():
        url = "http://cve.mitre.org/cgi-bin/cvename.cgi?name=" + CVE_QUEUE.get()
        print "download url:%s" % url
        download_html_file(url)
        time.sleep(0.5)
    print "[*] this thread is end."

def signal_handler(signum, frame):
    print "You choose to stop me."
    sys.exit()

if __name__ == "__main__":
    # url = "http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-1999-1521"
    # url = "http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-1999-0885"
    # download_html_file(url)

    # Step 1: Get all the CVE-ID
    get_cve_id()

    # Step 2: Launch all the process
    try:
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

        threads = []
        # Producer: spider cve info thread
        i = 0
        for i in range(THREAD_NUM):
            print "[*] Spawning thread: %d" % i
            t = Thread(target=spider_cve_info_handler)
            threads.append(t)

        # Consumer: upload cve info thread
        print "[*] Spawning thread: %d" % (i+1)
        t = Thread(target=upload_cve_info_handler)
        threads.append(t)

        for t in threads:
            t.setDaemon(True)
            t.start()

        while True:
            alive = False
            for i in range(THREAD_NUM):
                alive = alive or threads[i].isAlive()
            if not alive:
                break

    except Exception,e:
        logging.error("start thread error," + str(e))


